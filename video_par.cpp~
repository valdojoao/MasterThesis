
#include "vd_tracker.h"
#include "vd_features.h"

int main(int argc, char *argv[]){				/** @function main */



	for (size_t i = 0; i < 15; i++){ 			//initialize all face tracking variables

		track_face[i] 	= false;
		selectObject[i]	= false;
		timer[i]	= 0;
		trackObject[i]	= 0;
		sleeptime[i]	= 0;
	}

	VideoCapture capture("vid.mp4");					// var to capture video from camera
	UMat frame;						// n-dimensional array to store frame data

	loadCascades();						// Load the cascades

	// Read the video stream or image	
	if (!argv[1]){						// no input image, go to video stream  
//		capture.open(-1);				// open webcam

		//if (!capture.isOpened()) { printf("--(!)Error opening video capture\n");} 
		//else capture("vid.mp4");

		//Start the clock in order to find the FPS
		time_t start, end;	
		time(&start);	
		int counter=0;

		while (capture.read(frame)){

			if (frame.empty()){ printf(" --(!) No captured frame -- Break!"); break; }

			printf ("img size: %dx%d\n", frame.size().width, frame.size().height);			

			detectAndDisplay(frame); 		// compute

			//Stop the clock and show FPS
			time(&end);
			++counter;
			double sec=difftime(end,start);
		 	double fps=counter/sec;
			//printf("FPS: %f\n",fps);

			int c = waitKey(10);
			if ((char)c == 27) break;  		//escape
		} 
		destroyWindow("Face detection");		//deallocate any associated memory usage*/
	}
	else{ 

		ffTime(START_TIME);

		struct timespec t_init, now;

		clock_gettime(CLOCK_MONOTONIC, &t_init);
		frame = imread(argv[1]).getUMat(ACCESS_READ); 			// read image 
		clock_gettime(CLOCK_MONOTONIC, &now);

		printf ("Frame read in: %4.3f [ms]\n", diff(t_init, now).tv_nsec/1000000.0);

		isFrameImage = true;				

		printf ("img size: %dx%d\n", frame.size().width, frame.size().height);

		detectAndDisplay(frame);			// compute	

		ffTime(STOP_TIME);
		printf ("total time: %4.3f [ms]\n", ffTime(GET_TIME));
		cvWaitKey(0);
		destroyWindow("Face detection");		//deallocate any associated memory usage
		return 0;
	}
} 


void detectAndDisplay(UMat frame){			/** @function detectAndDisplay */

	
	vector<Rect> faces;				// create a list of rectangles for faces
	
	UMat frame_gray;				// create n-dimensional array of gray frame

	struct timespec t_gray, now_gray, t_hist, now_hist, t_face, now_face, t_clahe, now_clahe, showInit, showEnd, pInit, pEnd;

	clock_gettime(CLOCK_MONOTONIC, &t_gray);
	cvtColor(frame, frame_gray, COLOR_BGR2GRAY);	// convert frame to gray scale 	
	clock_gettime(CLOCK_MONOTONIC, &now_gray);
	printf ("gray scale computed in: %4.3f [ms]\n", diff(t_gray,now_gray).tv_nsec/1000000.0);

	//MUST BE TIME 
	if(bright_contrats < 100){	
		clock_gettime(CLOCK_MONOTONIC, &t_hist);
		equalizeHist(frame_gray, frame_gray);		// compute the integral image - equalizeHist(src, dest) 
		clock_gettime(CLOCK_MONOTONIC, &now_hist);
		printf ("histogram computed in: %4.3f [ms]\n", diff(t_hist,now_hist).tv_nsec/1000000.0);

		isClahe = false;
	}else{	

		clock_gettime(CLOCK_MONOTONIC, &t_clahe);
		Ptr<CLAHE> clahe = createCLAHE();
		clahe->setClipLimit(4);
		clahe->apply(frame_gray, frame_gray);
		clock_gettime(CLOCK_MONOTONIC, &now_clahe);
		printf ("clahe computed in: %4.3f [ms]\n", diff(t_clahe,now_clahe).tv_nsec/1000000.0);
		
		isClahe = true;
		if(bright_contrats > 150){
			bright_contrats = 0;
			isClahe = false;
		}
	}

	
	//Divide the screen in four parts:
	
	Rect rect[4];
	rect[0] =  Rect(frame.cols/4, frame.rows/10, frame.cols/2, frame.rows/1.3);	//1: center

	
	for (int y = 0; y < frame.rows; y += frame.rows)				//2: right half and 3: left half
	{
		int n = 1;
		for (int x = 0; x < frame.cols; x += frame.cols/2)
		{
			rect[n] =  Rect(x,y, frame.cols/2, frame.rows);
			n++;
		}
	}

	rect[3] =  Rect(0, 0, frame.cols, frame.rows);					//4: fullscreen


/*
	//show each of the parts
	for (int i = 0; i < 3; i++)
	{
		Point pt11(rect[i].x, rect[i].y);
		Point pt22(pt11.x + rect[i].width, pt11.y + rect[i].height);
		rectangle(frame, pt11, pt22, Scalar(i*100, i*100, i*100), 2, 8, 0);
	}
*/
	int window_num =  3;		// var to control which part of the screen face was detected


	for (size_t k = 0; k < max_num_faces; k++){	 
		if(!track_face[k]){ 			//if face is not detected, apply haarcascade to detect it

			/************************************************************************
			 * detectMultiScale(mat, vector, sf, mn, flag, minsize)	          	*
			 * sf: how much image size is reduced at each image scale 		* 
			 * mn: how many neighbors each candidate rectange should retain 	*
			 * minsize: objects smaller than that are ignored			*
			 **********************************************************************/

			//printf ("cntrast %d\n", bright_contrats);
			if(!isFrameImage && !faces.empty()){ 
				max_num_faces = faces.size(); 	//number of faces to track
				if(!isClahe) bright_contrats = 0;
				else bright_contrats = 100;
			}
			else bright_contrats++;

			
			//detect face in each of four parts, as soon as a face is the detected, terminate all the other parts and exit loop

			#pragma omp parallel for  num_threads(4)
			for(size_t j = 0; j < 4; j++){				
					
				 if(j == 0) { clock_gettime(CLOCK_MONOTONIC, &t_face);
					face_cascade.detectMultiScale(frame_gray(rect[0]), faces, 1.1, 2, 0|CASCADE_SCALE_IMAGE,
									Size(min_face_size, min_face_size)); 
					clock_gettime(CLOCK_MONOTONIC, &now_face);
					printf ("screen center: %d face(s) detected in: %4.3f [ms]\n", faces.size(), 
					diff(t_face,now_face).tv_nsec/1000000.0);
					if(!faces.empty()){ window_num = 0;
					 #pragma omp cancel for
					 }
 					} 
				
				 if(j == 1) { clock_gettime(CLOCK_MONOTONIC, &t_face);
					face_cascade.detectMultiScale(frame_gray(rect[1]), faces, 1.1, 2, 0|CASCADE_SCALE_IMAGE,
									Size(min_face_size, min_face_size)); 
					clock_gettime(CLOCK_MONOTONIC, &now_face);
					printf ("screen left: %d face(s) detected in: %4.3f [ms]\n", faces.size(), 
					diff(t_face,now_face).tv_nsec/1000000.0);
					if(!faces.empty()){ window_num = 1;
					 #pragma omp cancel for
					}
 				      } 

				 if(j == 2) { clock_gettime(CLOCK_MONOTONIC, &t_face);
					face_cascade.detectMultiScale(frame_gray(rect[2]), faces, 1.1, 2, 0|CASCADE_SCALE_IMAGE,
									Size(min_face_size, min_face_size)); 
					clock_gettime(CLOCK_MONOTONIC, &now_face);
					printf ("screen right: %d face(s) detected in: %4.3f [ms]\n", faces.size(), 
					diff(t_face,now_face).tv_nsec/1000000.0);
					if(!faces.empty()){ window_num = 2;
					 #pragma omp cancel for
					}
 					} 

				 if(j == 3) { clock_gettime(CLOCK_MONOTONIC, &t_face);
					face_cascade.detectMultiScale(frame_gray, faces, 1.1, 2, 0|CASCADE_SCALE_IMAGE, 									Size(min_face_size, min_face_size)); 
					clock_gettime(CLOCK_MONOTONIC, &now_face);
					printf ("full screen: %d face(s) detected in: %4.3f [ms]\n", faces.size(), 
					diff(t_face,now_face).tv_nsec/1000000.0);
					if(!faces.empty()){ 
					#pragma omp cancel for
					 }
					
					 }
					#pragma omp cancellation point for
						
			}


		//	#pragma omp parallel for  num_threads(faces.size()) schedule(dynamic,1)
			for (int i = 0; i < faces.size(); i++){ 	// for each detected face 		

				min_face_size = faces[0].width*0.8;	//define frame rate

				vector<Rect> eyes, lEyes, rEyes, lClosedEyes, rClosedEyes, mouth, nose;	// create a list of rectangles 
				bool boolFeature [4] = {false, false, false, false};

				
				#pragma omp parallel for num_threads(4) // schedule(dynamic,1)
				for(int j = 0; j < 4; j++){
				
				boolFeature [j] = computeFeature(j, faces, rEyes, rClosedEyes, lEyes, lClosedEyes,
									 mouth, nose, frame, frame_gray, i);

				}
/*
				ParallelFor pf;
				pf.parallel_for(0, 4, 1, [&boolFeature, &faces, &rEyes, &rClosedEyes, &lEyes,
				 &lClosedEyes, &mouth, &nose, &frame, &frame_gray, &i](const long j) {
     				 
					boolFeature [j] = computeFeature(j, faces, rEyes, rClosedEyes, lEyes, lClosedEyes,
                                                                         mouth, nose, frame, frame_gray, i);
   				 });
*/
				//in order to eliminate false positives, show face only if at least one of the features is found
				if(boolFeature[0] || boolFeature[1] || boolFeature[2] || boolFeature[3]) { 
					//variables to track the face so that we dont need to detect it again	


					selection[i].x 	= faces[i].x;
					selection[i].y 	= faces[i].y ;
					selection[i].width = faces[i].width;
					selection[i].height= faces[i].height;

					trackObject[i] 	= -1;
					track_face[i] 	= true;
					selection[i] &= Rect(0, 0, frame.cols, frame.rows);

					 showFace(faces, frame, i);					
				}
				else printf ("candidate face[%d]: is false positive\n", i); 

			} 
		}
		//face was already detected, track it
		else	track(frame, frame_gray, trackObject[k], selection[k], k);	
	} 
	
	clock_gettime(CLOCK_MONOTONIC, &showInit);
	namedWindow("Face detection", WINDOW_NORMAL);
	imshow("Face detection", frame);	// Show final result
	clock_gettime(CLOCK_MONOTONIC, &showEnd);
	printf ("Time to show the results: %4.3f [ms]\n", diff(showInit, showEnd).tv_nsec/1000000.0);
}
